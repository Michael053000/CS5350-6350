# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lfzMpOgGk6Bfvb4o6rt0XYVf_qHb4mZ0
"""

import numpy as np
import pandas as pd
import os

# Define directory paths for data files
base_dir = "/content/bank-note"  # Replace with your actual path
train_file = os.path.join(base_dir, 'train.csv')
data_txt = os.path.join(base_dir, 'data-desc')
test_file = os.path.join(base_dir, 'test.csv')

def read_data_description(desc_path):
    """
    Reads and prints the data description from a text file.
    Args:
    - desc_path (str): Path to the data description file.
    """
    with open(desc_path, 'r') as f:
        data_desc = f.read()
    print("Data Description:")
    print(data_desc)
    print("\nFeatures will be loaded according to this description.")

def load_and_preprocess_data():
    """
    Loads and preprocesses the train and test datasets.
    - Reads the data description.
    - Loads train and test data.
    - Converts labels from {0,1} to {-1,1} for compatibility with perceptron training.

    Returns:
    - X_train (ndarray): Training features.
    - y_train (ndarray): Training labels.
    - X_test (ndarray): Test features.
    - y_test (ndarray): Test labels.
    """
    read_data_description(data_txt)

    # Load train and test data, assuming no headers in CSV files
    train_data = pd.read_csv(train_file, header=None)
    test_data = pd.read_csv(test_file, header=None)

    # Separate features and labels
    X_train, y_train = train_data.iloc[:, :-1].values, train_data.iloc[:, -1].values
    X_test, y_test = test_data.iloc[:, :-1].values, test_data.iloc[:, -1].values

    # Convert labels from {0,1} to {-1,1}
    y_train = 2 * y_train - 1
    y_test = 2 * y_test - 1

    print(f"\nDataset Statistics:\nTraining set: {len(X_train)} examples\nTest set: {len(X_test)} examples\nNumber of features: {X_train.shape[1]}")

    return X_train, y_train, X_test, y_test

class Perceptron:
    """
    Base Perceptron class with common methods for different perceptron variations.
    """
    def __init__(self, max_epochs=10):
        self.max_epochs = max_epochs

    def predict(self, X):
        raise NotImplementedError("Predict method needs to be implemented in subclasses")

class StandardPerceptron(Perceptron):
    """
    Standard Perceptron model implementation.
    """
    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.weights = np.zeros(n_features)
        self.bias = 0

        # Update rule for standard perceptron
        for _ in range(self.max_epochs):
            for i in range(n_samples):
                prediction = np.sign(np.dot(X[i], self.weights) + self.bias)
                if prediction != y[i]:  # Update if prediction is incorrect
                    self.weights += y[i] * X[i]
                    self.bias += y[i]

    def predict(self, X):
        return np.sign(np.dot(X, self.weights) + self.bias)

class VotedPerceptron(Perceptron):
    """
    Voted Perceptron model implementation.
    """
    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.weights_list, self.bias_list, self.counts_list = [], [], []

        current_weights = np.zeros(n_features)
        current_bias = 0
        current_count = 0

        # Train with voting mechanism
        for _ in range(self.max_epochs):
            for i in range(n_samples):
                prediction = np.sign(np.dot(X[i], current_weights) + current_bias)
                if prediction == y[i]:
                    current_count += 1
                else:
                    # Record current weights, bias, and count before updating
                    if current_count > 0:
                        self.weights_list.append(current_weights.copy())
                        self.bias_list.append(current_bias)
                        self.counts_list.append(current_count)

                    # Update weights and bias based on misclassified sample
                    current_weights += y[i] * X[i]
                    current_bias += y[i]
                    current_count = 1

        # Append the last set of weights if any count left
        if current_count > 0:
            self.weights_list.append(current_weights.copy())
            self.bias_list.append(current_bias)
            self.counts_list.append(current_count)

    def predict(self, X):
        predictions = np.zeros(len(X))
        # Weighted voting for final prediction
        for i in range(len(X)):
            vote = sum(count * np.sign(np.dot(X[i], weights) + bias)
                       for weights, bias, count in zip(self.weights_list, self.bias_list, self.counts_list))
            predictions[i] = np.sign(vote)
        return predictions

class AveragePerceptron(Perceptron):
    """
    Average Perceptron model implementation.
    """
    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.weights = np.zeros(n_features)
        self.bias = 0
        self.avg_weights = np.zeros(n_features)
        self.avg_bias = 0
        update_count = 1

        # Train with averaging mechanism
        for _ in range(self.max_epochs):
            for i in range(n_samples):
                prediction = np.sign(np.dot(X[i], self.weights) + self.bias)
                if prediction != y[i]:  # Update if prediction is incorrect
                    self.weights += y[i] * X[i]
                    self.bias += y[i]

                # Accumulate weights and bias for averaging
                self.avg_weights += self.weights
                self.avg_bias += self.bias
                update_count += 1

        # Average the weights and bias
        self.avg_weights /= update_count
        self.avg_bias /= update_count

    def predict(self, X):
        return np.sign(np.dot(X, self.avg_weights) + self.avg_bias)

def calculate_error(y_true, y_pred):
    """
    Calculates error rate between true and predicted labels.
    """
    return np.mean(y_true != y_pred)

if __name__ == "__main__":
    # Load and preprocess data
    X_train, y_train, X_test, y_test = load_and_preprocess_data()

    # Initialize perceptron models
    perceptrons = {
        "Standard": StandardPerceptron(max_epochs=10),
        "Voted": VotedPerceptron(max_epochs=10),
        "Average": AveragePerceptron(max_epochs=10)
    }

    # Train and test each perceptron model
    for name, perceptron in perceptrons.items():
        print(f"\nTesting {name} Perceptron:")
        perceptron.fit(X_train, y_train)
        test_predictions = perceptron.predict(X_test)
        error = calculate_error(y_test, test_predictions)
        print(f"Average prediction error on test set: {error:.6f}")

        # Display model-specific parameters and statistics
        if name == "Standard":
            print("\nLearned weight vector:")
            print(f"Weights: {perceptron.weights}\nBias: {perceptron.bias}")
        elif name == "Voted":
            print("\nWeight vectors and their counts:")
            for i, (weights, bias, count) in enumerate(zip(
                perceptron.weights_list, perceptron.bias_list, perceptron.counts_list)):
                print(f"Vector {i+1}: Weights: {weights}, Bias: {bias}, Count: {count}")
        else:
            print("\nLearned average weight vector:")
            print(f"Weights: {perceptron.avg_weights}\nBias: {perceptron.avg_bias}")